{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporrt Libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_hospital = pd.read_csv(\"./Data/Hospital_Dataset_2020_2024.csv\")\n",
    "df_air = pd.read_csv(\"./Data/Air_Quality - بيانات جودة الهواء في السعودية.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   date               120000 non-null  object \n",
      " 1   city               120000 non-null  object \n",
      " 2   station            120000 non-null  object \n",
      " 3   component          120000 non-null  object \n",
      " 4   value              120000 non-null  int64  \n",
      " 5   unit               120000 non-null  object \n",
      " 6   indicator          120000 non-null  object \n",
      " 7   periodicity        120000 non-null  object \n",
      " 8   quarter            120000 non-null  float64\n",
      " 9   temperature (Â0C)  120000 non-null  float64\n",
      " 10  humidity (%)       120000 non-null  float64\n",
      " 11  wind_speed (km/h)  120000 non-null  int64  \n",
      " 12  PM2.5              120000 non-null  int64  \n",
      " 13  PM10               0 non-null       float64\n",
      "dtypes: float64(4), int64(3), object(7)\n",
      "memory usage: 12.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41544 entries, 0 to 41543\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   admission_date             41544 non-null  object \n",
      " 1   hospital_name              41544 non-null  object \n",
      " 2   admission_count            41544 non-null  int64  \n",
      " 3   condition_type             41544 non-null  object \n",
      " 4   patient_age_group          41544 non-null  object \n",
      " 5   patient_gender             41544 non-null  object \n",
      " 6   readmission_count          41544 non-null  int64  \n",
      " 7   severity_level             41544 non-null  object \n",
      " 8   length_of_stay_avg         41544 non-null  float64\n",
      " 9   seasonal_indicator         41544 non-null  object \n",
      " 10  comorbid_conditions_count  41544 non-null  int64  \n",
      " 11  primary_diagnosis_code     41544 non-null  object \n",
      " 12  daily_medication_dosage    41544 non-null  float64\n",
      " 13  emergency_visit_count      41544 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 4.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                  date    city      station component  value          unit  \\\n",
       " 0  2022-01-01 0:00:00  Dammam   Grantville       NO2     44   mg/mÂ3ŹHigh   \n",
       " 1  2022-01-01 1:00:00  Dammam  North Erica      PM10    180   mg/mÂ3ŹHigh   \n",
       " 2  2022-01-01 2:00:00  Riyadh  Lake Mariah       NO2    135   Â5g/mÂ3ŹLow   \n",
       " 3  2022-01-01 3:00:00  Riyadh   Collinview      PM10     35  Â5g/mÂ3ŹHigh   \n",
       " 4  2022-01-01 4:00:00  Riyadh  Lake Mariah        CO    290   mg/mÂ3ŹHigh   \n",
       " \n",
       "   indicator periodicity  quarter  temperature (Â0C)  humidity (%)  \\\n",
       " 0     Daily          Q1    36.91              48.23          7.74   \n",
       " 1     Daily          Q3    32.28              51.47         34.99   \n",
       " 2     Daily          Q1    27.01              38.85         35.26   \n",
       " 3     Daily          Q3    33.29              47.80          3.05   \n",
       " 4     Daily          Q3    15.43              20.38         32.33   \n",
       " \n",
       "    wind_speed (km/h)  PM2.5  PM10  \n",
       " 0                 17    177   NaN  \n",
       " 1                 32    194   NaN  \n",
       " 2                 70     97   NaN  \n",
       " 3                 82    112   NaN  \n",
       " 4                118    109   NaN  ,\n",
       " None,\n",
       "         admission_date               hospital_name  admission_count  \\\n",
       " 0  2020-01-01 00:00:00         Mecca City Hospital                1   \n",
       " 1  2020-01-01 01:00:00     Dammam General Hospital                2   \n",
       " 2  2020-01-01 02:00:00         Mecca City Hospital                1   \n",
       " 3  2020-01-01 03:00:00  Medina Specialist Hospital                3   \n",
       " 4  2020-01-01 04:00:00  Medina Specialist Hospital                5   \n",
       " \n",
       "   condition_type patient_age_group patient_gender  readmission_count  \\\n",
       " 0         Asthma             46-65         Female                  0   \n",
       " 1         Asthma              0-17         Female                  1   \n",
       " 2         Asthma             46-65         Female                  1   \n",
       " 3         Asthma             46-65           Male                  0   \n",
       " 4           COPD             18-45         Female                  2   \n",
       " \n",
       "   severity_level  length_of_stay_avg seasonal_indicator  \\\n",
       " 0       Moderate            2.781828             Winter   \n",
       " 1           Mild            4.141432             Winter   \n",
       " 2       Moderate            8.507026             Winter   \n",
       " 3           Mild            4.622657             Winter   \n",
       " 4       Moderate            5.818385             Winter   \n",
       " \n",
       "    comorbid_conditions_count primary_diagnosis_code  daily_medication_dosage  \\\n",
       " 0                          1                  Other                17.455517   \n",
       " 1                          0                  Other                15.099498   \n",
       " 2                          2                    I21                23.087843   \n",
       " 3                          3                    J45                25.247579   \n",
       " 4                          3                    J45                18.255290   \n",
       " \n",
       "    emergency_visit_count  \n",
       " 0                      2  \n",
       " 1                      3  \n",
       " 2                      3  \n",
       " 3                      2  \n",
       " 4                      1  )"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Basic Information\n",
    "# Display basic info and first few rows\n",
    "df_air_info = df_air.info()\n",
    "df_hospital_info = df_hospital.info()\n",
    "\n",
    "df_air_head = df_air.head()\n",
    "df_hospital_head = df_hospital.head()\n",
    "\n",
    "df_air_info, df_air_head, df_hospital_info, df_hospital_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clean column names\n",
    "df_air.rename(columns={\"temperature (Â0C)\": \"temperature\", \"humidity (%)\": \"humidity\"}, inplace=True)\n",
    "\n",
    "# Step 2: Drop empty PM10 column\n",
    "df_air.drop(columns=[\"PM10\"], inplace=True)\n",
    "\n",
    "# Step 3: Convert date columns to datetime format\n",
    "df_air[\"date\"] = pd.to_datetime(df_air[\"date\"], errors=\"coerce\")\n",
    "df_hospital[\"admission_date\"] = pd.to_datetime(df_hospital[\"admission_date\"], errors=\"coerce\")\n",
    "\n",
    "# Step 4: Extract useful time features\n",
    "df_air[\"year\"] = df_air[\"date\"].dt.year\n",
    "df_air[\"month\"] = df_air[\"date\"].dt.month\n",
    "df_air[\"day\"] = df_air[\"date\"].dt.day\n",
    "df_air[\"hour\"] = df_air[\"date\"].dt.hour\n",
    "\n",
    "df_hospital[\"year\"] = df_hospital[\"admission_date\"].dt.year\n",
    "df_hospital[\"month\"] = df_hospital[\"admission_date\"].dt.month\n",
    "df_hospital[\"day\"] = df_hospital[\"admission_date\"].dt.day\n",
    "df_hospital[\"hour\"] = df_hospital[\"admission_date\"].dt.hour\n",
    "\n",
    "# Step 5: Clean unit column (remove strange characters)\n",
    "df_air[\"unit\"] = df_air[\"unit\"].str.replace(r\"[^\\w\\s]\", \"\", regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Mecca City Hospital', 'Dammam General Hospital',\n",
       "        'Medina Specialist Hospital', 'Dammam Central Hospital',\n",
       "        'King Saud Hospital', 'Jeddah National Hospital',\n",
       "        'Riyadh National Hospital', 'Riyadh General Hospital'],\n",
       "       dtype=object),\n",
       " array(['Dammam', 'Riyadh', 'Medina', 'Jeddah', 'Mecca'], dtype=object),\n",
       " (Timestamp('2020-01-01 00:00:00'), Timestamp('2024-09-26 23:00:00')),\n",
       " (Timestamp('2022-01-01 00:00:00'), Timestamp('2024-09-26 23:00:00')))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values in city columns to compare naming conventions\n",
    "hospital_cities = df_hospital[\"hospital_name\"].unique()\n",
    "air_quality_cities = df_air[\"city\"].unique()\n",
    "\n",
    "# Check date range in both datasets\n",
    "hospital_date_range = (df_hospital[\"admission_date\"].min(), df_hospital[\"admission_date\"].max())\n",
    "air_quality_date_range = (df_air[\"date\"].min(), df_air[\"date\"].max())\n",
    "\n",
    "hospital_cities, air_quality_cities, hospital_date_range, air_quality_date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a mapping of hospital names to their corresponding cities\n",
    "hospital_to_city = {\n",
    "    \"Mecca City Hospital\": \"Mecca\",\n",
    "    \"Dammam General Hospital\": \"Dammam\",\n",
    "    \"Medina Specialist Hospital\": \"Medina\",\n",
    "    \"Dammam Central Hospital\": \"Dammam\",\n",
    "    \"King Saud Hospital\": \"Riyadh\",\n",
    "    \"Jeddah National Hospital\": \"Jeddah\",\n",
    "    \"Riyadh National Hospital\": \"Riyadh\",\n",
    "    \"Riyadh General Hospital\": \"Riyadh\",\n",
    "}\n",
    "\n",
    "# Step 2: Create a new column in the hospital dataset with the mapped city names\n",
    "df_hospital[\"city\"] = df_hospital[\"hospital_name\"].map(hospital_to_city)\n",
    "\n",
    "# Step 3: Filter hospital dataset to match air quality date range (2022+)\n",
    "df_hospital_filtered = df_hospital[df_hospital[\"admission_date\"] >= \"2022-01-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44285 entries, 0 to 44284\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   date                       44285 non-null  datetime64[ns]\n",
      " 1   hospital_name              44285 non-null  object        \n",
      " 2   admission_count            44285 non-null  int64         \n",
      " 3   condition_type             44285 non-null  object        \n",
      " 4   patient_age_group          44285 non-null  object        \n",
      " 5   patient_gender             44285 non-null  object        \n",
      " 6   readmission_count          44285 non-null  int64         \n",
      " 7   severity_level             44285 non-null  object        \n",
      " 8   length_of_stay_avg         44285 non-null  float64       \n",
      " 9   seasonal_indicator         44285 non-null  object        \n",
      " 10  comorbid_conditions_count  44285 non-null  int64         \n",
      " 11  primary_diagnosis_code     44285 non-null  object        \n",
      " 12  daily_medication_dosage    44285 non-null  float64       \n",
      " 13  emergency_visit_count      44285 non-null  int64         \n",
      " 14  year_x                     44285 non-null  int32         \n",
      " 15  month_x                    44285 non-null  int32         \n",
      " 16  day_x                      44285 non-null  int32         \n",
      " 17  hour_x                     44285 non-null  int32         \n",
      " 18  city                       44285 non-null  object        \n",
      " 19  station                    35666 non-null  object        \n",
      " 20  component                  35666 non-null  object        \n",
      " 21  value                      35666 non-null  float64       \n",
      " 22  unit                       35666 non-null  object        \n",
      " 23  indicator                  35666 non-null  object        \n",
      " 24  periodicity                35666 non-null  object        \n",
      " 25  quarter                    35666 non-null  float64       \n",
      " 26  temperature                35666 non-null  float64       \n",
      " 27  humidity                   35666 non-null  float64       \n",
      " 28  wind_speed (km/h)          35666 non-null  float64       \n",
      " 29  PM2.5                      35666 non-null  float64       \n",
      " 30  year_y                     35666 non-null  float64       \n",
      " 31  month_y                    35666 non-null  float64       \n",
      " 32  day_y                      35666 non-null  float64       \n",
      " 33  hour_y                     35666 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int32(4), int64(4), object(13)\n",
      "memory usage: 10.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                  date            hospital_name  admission_count  \\\n",
       " 0 2022-01-01 00:00:00  Riyadh General Hospital                2   \n",
       " 1 2022-01-01 00:00:00  Riyadh General Hospital                2   \n",
       " 2 2022-01-01 01:00:00  Dammam General Hospital                1   \n",
       " 3 2022-01-01 02:00:00  Riyadh General Hospital                3   \n",
       " 4 2022-01-01 02:00:00  Riyadh General Hospital                3   \n",
       " \n",
       "   condition_type patient_age_group patient_gender  readmission_count  \\\n",
       " 0         Asthma             18-45           Male                  0   \n",
       " 1         Asthma             18-45           Male                  0   \n",
       " 2         Asthma             18-45         Female                  0   \n",
       " 3         Asthma             18-45         Female                  0   \n",
       " 4         Asthma             18-45         Female                  0   \n",
       " \n",
       "   severity_level  length_of_stay_avg seasonal_indicator  ...  periodicity  \\\n",
       " 0         Severe            3.775284             Winter  ...           Q1   \n",
       " 1         Severe            3.775284             Winter  ...           Q1   \n",
       " 2       Moderate            2.857317             Winter  ...           Q3   \n",
       " 3       Moderate            4.391828             Winter  ...           Q1   \n",
       " 4       Moderate            4.391828             Winter  ...           Q3   \n",
       " \n",
       "   quarter  temperature  humidity  wind_speed (km/h)  PM2.5  year_y  month_y  \\\n",
       " 0   28.07        32.08     24.25               17.0   70.0  2022.0      1.0   \n",
       " 1   19.78        79.58      4.01               70.0   85.0  2022.0      1.0   \n",
       " 2   32.28        51.47     34.99               32.0  194.0  2022.0      1.0   \n",
       " 3   27.01        38.85     35.26               70.0   97.0  2022.0      1.0   \n",
       " 4   20.85        75.63     16.14               70.0   44.0  2022.0      1.0   \n",
       " \n",
       "   day_y hour_y  \n",
       " 0   1.0    0.0  \n",
       " 1   1.0    0.0  \n",
       " 2   1.0    1.0  \n",
       " 3   1.0    2.0  \n",
       " 4   1.0    2.0  \n",
       " \n",
       " [5 rows x 34 columns])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename \"admission_date\" in hospital dataset to match air quality dataset\n",
    "df_hospital_filtered = df_hospital_filtered.rename(columns={\"admission_date\": \"date\"})\n",
    "\n",
    "# Retry merging with the corrected column names\n",
    "merged_df_fixed = df_hospital_filtered.merge(df_air, on=[\"city\", \"date\"], how=\"left\")\n",
    "\n",
    "# Check merge success\n",
    "merged_df_fixed.info(), merged_df_fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'wind_speed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wind_speed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Step 4: Environmental interaction features\u001b[39;00m\n\u001b[1;32m     18\u001b[0m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp_humidity_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhumidity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind_PM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPM2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Step 5: Encode severity levels\u001b[39;00m\n\u001b[1;32m     22\u001b[0m severity_mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMild\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModerate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSevere\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wind_speed'"
     ]
    }
   ],
   "source": [
    "# Step 1: Re-extract date features\n",
    "merged_df_fixed[\"month\"] = merged_df_fixed[\"date\"].dt.month\n",
    "merged_df_fixed[\"day\"] = merged_df_fixed[\"date\"].dt.day\n",
    "merged_df_fixed[\"hour\"] = merged_df_fixed[\"date\"].dt.hour\n",
    "\n",
    "# Step 2: Create season feature again\n",
    "merged_df_fixed[\"season\"] = merged_df_fixed[\"month\"].map({\n",
    "    12: \"Winter\", 1: \"Winter\", 2: \"Winter\",\n",
    "    3: \"Spring\", 4: \"Spring\", 5: \"Spring\",\n",
    "    6: \"Summer\", 7: \"Summer\", 8: \"Summer\",\n",
    "    9: \"Fall\", 10: \"Fall\", 11: \"Fall\"\n",
    "})\n",
    "\n",
    "# Step 3: Recreate weekend feature\n",
    "merged_df_fixed[\"weekend\"] = merged_df_fixed[\"date\"].dt.weekday.isin([4, 5]).astype(int)\n",
    "\n",
    "# Step 4: Environmental interaction features\n",
    "merged_df_fixed[\"temp_humidity_index\"] = merged_df_fixed[\"temperature\"] * merged_df_fixed[\"humidity\"]\n",
    "merged_df_fixed[\"wind_PM\"] = merged_df_fixed[\"wind_speed\"] * merged_df_fixed[\"PM2.5\"]\n",
    "\n",
    "# Step 5: Encode severity levels\n",
    "severity_mapping = {\"Mild\": 1, \"Moderate\": 2, \"Severe\": 3}\n",
    "merged_df_fixed[\"severity_numeric\"] = merged_df_fixed[\"severity_level\"].map(severity_mapping)\n",
    "\n",
    "# Step 6: Emergency visit ratio\n",
    "merged_df_fixed[\"emergency_ratio\"] = merged_df_fixed[\"emergency_visit_count\"] / (merged_df_fixed[\"admission_count\"] + 1)\n",
    "\n",
    "# Check new features\n",
    "merged_df_fixed[[\"season\", \"weekend\", \"temp_humidity_index\", \"wind_PM\", \"severity_numeric\", \"emergency_ratio\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which columns from the air quality dataset are missing after merging\n",
    "missing_cols = [col for col in df_air.columns if col not in merged_df_fixed.columns]\n",
    "missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: wind_speed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m air_quality_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPM2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhumidity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSO2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m air_quality_cols:\n\u001b[0;32m----> 5\u001b[0m     merged_df_fixed[col] \u001b[38;5;241m=\u001b[39m merged_df_fixed\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m])[col]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mfillna(x\u001b[38;5;241m.\u001b[39mmedian()))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Retry creating wind_PM feature\u001b[39;00m\n\u001b[1;32m      8\u001b[0m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind_PM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwind_speed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPM2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: wind_speed'"
     ]
    }
   ],
   "source": [
    "# Fill missing values in air quality columns using the median per city & month\n",
    "air_quality_cols = [\"PM2.5\", \"temperature\", \"humidity\", \"wind_speed\", \"NO2\", \"SO2\"]\n",
    "\n",
    "for col in air_quality_cols:\n",
    "    merged_df_fixed[col] = merged_df_fixed.groupby([\"city\", \"month\"])[col].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Retry creating wind_PM feature\n",
    "merged_df_fixed[\"wind_PM\"] = merged_df_fixed[\"wind_speed\"] * merged_df_fixed[\"PM2.5\"]\n",
    "\n",
    "# Check if missing values are resolved\n",
    "merged_df_fixed[air_quality_cols].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'hospital_name', 'admission_count', 'condition_type',\n",
       "       'patient_age_group', 'patient_gender', 'readmission_count',\n",
       "       'severity_level', 'length_of_stay_avg', 'seasonal_indicator',\n",
       "       'comorbid_conditions_count', 'primary_diagnosis_code',\n",
       "       'daily_medication_dosage', 'emergency_visit_count', 'year_x', 'month_x',\n",
       "       'day_x', 'hour_x', 'city', 'station', 'component', 'value', 'unit',\n",
       "       'indicator', 'periodicity', 'quarter', 'temperature', 'humidity',\n",
       "       'wind_speed (km/h)', 'PM2.5', 'year_y', 'month_y', 'day_y', 'hour_y',\n",
       "       'month', 'day', 'hour', 'season', 'weekend', 'temp_humidity_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all column names in merged dataset\n",
    "merged_df_fixed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wind_speed    8619\n",
       "PM2.5            0\n",
       "wind_PM       8619\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename wind_speed column for consistency\n",
    "merged_df_fixed.rename(columns={\"wind_speed (km/h)\": \"wind_speed\"}, inplace=True)\n",
    "\n",
    "# Retry creating wind_PM feature\n",
    "merged_df_fixed[\"wind_PM\"] = merged_df_fixed[\"wind_speed\"] * merged_df_fixed[\"PM2.5\"]\n",
    "\n",
    "# Check if missing values are resolved\n",
    "merged_df_fixed[[\"wind_speed\", \"PM2.5\", \"wind_PM\"]].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wind_speed    0\n",
       "PM2.5         0\n",
       "wind_PM       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing wind_speed values with median per city & month\n",
    "merged_df_fixed[\"wind_speed\"] = merged_df_fixed.groupby([\"city\", \"month\"])[\"wind_speed\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Recalculate wind_PM feature\n",
    "merged_df_fixed[\"wind_PM\"] = merged_df_fixed[\"wind_speed\"] * merged_df_fixed[\"PM2.5\"]\n",
    "\n",
    "# Check again for missing values\n",
    "merged_df_fixed[[\"wind_speed\", \"PM2.5\", \"wind_PM\"]].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'hospital_name', 'admission_count', 'condition_type',\n",
       "       'patient_age_group', 'patient_gender', 'readmission_count',\n",
       "       'severity_level', 'length_of_stay_avg', 'seasonal_indicator',\n",
       "       'comorbid_conditions_count', 'primary_diagnosis_code',\n",
       "       'daily_medication_dosage', 'emergency_visit_count', 'year_x', 'month_x',\n",
       "       'day_x', 'hour_x', 'city', 'station', 'component', 'value', 'unit',\n",
       "       'indicator', 'periodicity', 'quarter', 'temperature', 'humidity',\n",
       "       'wind_speed', 'PM2.5', 'year_y', 'month_y', 'day_y', 'hour_y', 'month',\n",
       "       'day', 'hour', 'season', 'weekend', 'temp_humidity_index', 'wind_PM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available columns in the dataset\n",
    "merged_df_fixed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NO2', 'SO2'],\n",
       " severity_numeric    0\n",
       " emergency_ratio     0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Check if NO2 and SO2 exist in the original air quality dataset\n",
    "missing_pollutants = [col for col in [\"NO2\", \"SO2\"] if col not in df_air.columns]\n",
    "\n",
    "# Step 2: Recreate severity_numeric\n",
    "severity_mapping = {\"Mild\": 1, \"Moderate\": 2, \"Severe\": 3}\n",
    "merged_df_fixed[\"severity_numeric\"] = merged_df_fixed[\"severity_level\"].map(severity_mapping)\n",
    "\n",
    "# Step 3: Recalculate emergency_ratio\n",
    "merged_df_fixed[\"emergency_ratio\"] = merged_df_fixed[\"emergency_visit_count\"] / (merged_df_fixed[\"admission_count\"] + 1)\n",
    "\n",
    "# Step 4: Verify if fixes were applied\n",
    "missing_pollutants, merged_df_fixed[[\"severity_numeric\", \"emergency_ratio\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['NO2', 'SO2'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m LabelEncoder()\u001b[38;5;241m.\u001b[39mfit_transform(merged_df_fixed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseason\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Step 3: Split data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m X \u001b[38;5;241m=\u001b[39m merged_df_fixed[features]\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m merged_df_fixed[target]\n\u001b[1;32m     18\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['NO2', 'SO2'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Select features and target variable\n",
    "features = [\"temperature\", \"humidity\", \"wind_speed\", \"PM2.5\", \"NO2\", \"SO2\",\n",
    "            \"season\", \"weekend\", \"temp_humidity_index\", \"wind_PM\", \"severity_numeric\", \"emergency_ratio\"]\n",
    "\n",
    "target = \"admission_count\"  # Predicting hospital admissions\n",
    "\n",
    "# Step 2: Encode categorical features\n",
    "merged_df_fixed[\"season\"] = LabelEncoder().fit_transform(merged_df_fixed[\"season\"])\n",
    "\n",
    "# Step 3: Split data\n",
    "X = merged_df_fixed[features]\n",
    "y = merged_df_fixed[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate models\n",
    "rf_mae, rf_mse, rf_r2 = mean_absolute_error(y_test, rf_preds), mean_squared_error(y_test, rf_preds), r2_score(y_test, rf_preds)\n",
    "gb_mae, gb_mse, gb_r2 = mean_absolute_error(y_test, gb_preds), mean_squared_error(y_test, gb_preds), r2_score(y_test, gb_preds)\n",
    "\n",
    "(rf_mae, rf_mse, rf_r2), (gb_mae, gb_mse, gb_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'hospital_name', 'admission_count', 'condition_type',\n",
       "       'patient_age_group', 'patient_gender', 'readmission_count',\n",
       "       'severity_level', 'length_of_stay_avg', 'seasonal_indicator',\n",
       "       'comorbid_conditions_count', 'primary_diagnosis_code',\n",
       "       'daily_medication_dosage', 'emergency_visit_count', 'year_x', 'month_x',\n",
       "       'day_x', 'hour_x', 'city', 'station', 'component', 'value', 'unit',\n",
       "       'indicator', 'periodicity', 'quarter', 'temperature', 'humidity',\n",
       "       'wind_speed', 'PM2.5', 'year_y', 'month_y', 'day_y', 'hour_y', 'month',\n",
       "       'day', 'hour', 'season', 'weekend', 'temp_humidity_index', 'wind_PM',\n",
       "       'severity_numeric', 'emergency_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available columns in the dataset\n",
    "merged_df_fixed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['NO2', 'SO2'],\n",
       " severity_numeric    0\n",
       " emergency_ratio     0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Check if NO2 and SO2 exist in the original air quality dataset\n",
    "missing_pollutants = [col for col in [\"NO2\", \"SO2\"] if col not in df_air.columns]\n",
    "\n",
    "# Step 2: Recreate severity_numeric\n",
    "severity_mapping = {\"Mild\": 1, \"Moderate\": 2, \"Severe\": 3}\n",
    "merged_df_fixed[\"severity_numeric\"] = merged_df_fixed[\"severity_level\"].map(severity_mapping)\n",
    "\n",
    "# Step 3: Recalculate emergency_ratio\n",
    "merged_df_fixed[\"emergency_ratio\"] = merged_df_fixed[\"emergency_visit_count\"] / (merged_df_fixed[\"admission_count\"] + 1)\n",
    "\n",
    "# Step 4: Verify if fixes were applied\n",
    "missing_pollutants, merged_df_fixed[[\"severity_numeric\", \"emergency_ratio\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nGradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Step 3: Retrain models\u001b[39;00m\n\u001b[1;32m     20\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 21\u001b[0m gb_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Step 4: Make predictions again\u001b[39;00m\n\u001b[1;32m     24\u001b[0m rf_preds \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:659\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_state()\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# Check input\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# Since check_array converts both X and y to the same dtype, but the\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# trees use different types for X and y, checking them separately.\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    660\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mDTYPE, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    661\u001b[0m )\n\u001b[1;32m    662\u001b[0m sample_weight_is_none \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    663\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     )\n\u001b[0;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1264\u001b[0m     X,\n\u001b[1;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1266\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1267\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1268\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1269\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1270\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1271\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1272\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1273\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1274\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1275\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1277\u001b[0m )\n\u001b[1;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1049\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1049\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1050\u001b[0m         array,\n\u001b[1;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:126\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    127\u001b[0m     X,\n\u001b[1;32m    128\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    129\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    130\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    131\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    132\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    133\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:175\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nGradientBoostingRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Re-import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Reinitialize models\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Step 1: Update feature list (remove NO2 and SO2)\n",
    "features = [\"temperature\", \"humidity\", \"wind_speed\", \"PM2.5\",  \n",
    "            \"season\", \"weekend\", \"temp_humidity_index\", \"wind_PM\", \"severity_numeric\", \"emergency_ratio\"]\n",
    "\n",
    "# Step 2: Split data again\n",
    "X = merged_df_fixed[features]\n",
    "y = merged_df_fixed[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Retrain models\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions again\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate models again\n",
    "rf_mae, rf_mse, rf_r2 = mean_absolute_error(y_test, rf_preds), mean_squared_error(y_test, rf_preds), r2_score(y_test, rf_preds)\n",
    "gb_mae, gb_mse, gb_r2 = mean_absolute_error(y_test, gb_preds), mean_squared_error(y_test, gb_preds), r2_score(y_test, gb_preds)\n",
    "\n",
    "(rf_mae, rf_mse, rf_r2), (gb_mae, gb_mse, gb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature               0\n",
       "humidity                  0\n",
       "wind_speed                0\n",
       "PM2.5                     0\n",
       "season                    0\n",
       "weekend                   0\n",
       "temp_humidity_index    8619\n",
       "wind_PM                   0\n",
       "severity_numeric          0\n",
       "emergency_ratio           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Check which columns have missing values\n",
    "missing_values = merged_df_fixed[features].isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5664/2197966736.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df_fixed[\"temp_humidity_index\"].fillna(merged_df_fixed[\"temp_humidity_index\"].median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "temperature            0\n",
       "humidity               0\n",
       "wind_speed             0\n",
       "PM2.5                  0\n",
       "season                 0\n",
       "weekend                0\n",
       "temp_humidity_index    0\n",
       "wind_PM                0\n",
       "severity_numeric       0\n",
       "emergency_ratio        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Fill missing values with median\n",
    "merged_df_fixed[\"temp_humidity_index\"].fillna(merged_df_fixed[\"temp_humidity_index\"].median(), inplace=True)\n",
    "\n",
    "# Step 2: Verify if all missing values are handled\n",
    "merged_df_fixed[features].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6697335369437356, 1.079400667682128, 0.4545148700053926),\n",
       " (0.6814494974942417, 1.0259197867844583, 0.4815419287632279))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Split data again (now clean)\n",
    "X = merged_df_fixed[features]\n",
    "y = merged_df_fixed[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Retrain models\n",
    "rf_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Make predictions\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "gb_preds = gb_model.predict(X_test)\n",
    "\n",
    "# Step 4: Evaluate models\n",
    "rf_mae, rf_mse, rf_r2 = mean_absolute_error(y_test, rf_preds), mean_squared_error(y_test, rf_preds), r2_score(y_test, rf_preds)\n",
    "gb_mae, gb_mse, gb_r2 = mean_absolute_error(y_test, gb_preds), mean_squared_error(y_test, gb_preds), r2_score(y_test, gb_preds)\n",
    "\n",
    "(rf_mae, rf_mse, rf_r2), (gb_mae, gb_mse, gb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200},\n",
       " {'learning_rate': 0.05,\n",
       "  'max_depth': 5,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 100})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grids for both models\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for both models\n",
    "rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "gb_grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), gb_param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Run GridSearchCV for Random Forest\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "# Run GridSearchCV for Gradient Boosting\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "best_gb = gb_grid_search.best_estimator_\n",
    "\n",
    "# Get best parameters\n",
    "rf_best_params = rf_grid_search.best_params_\n",
    "gb_best_params = gb_grid_search.best_params_\n",
    "\n",
    "rf_best_params, gb_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(learning_rate=0.05, max_depth=5, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.05, max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Train Random Forest with best parameters\n",
    "rf_best = RandomForestRegressor(max_depth=10, min_samples_split=5, n_estimators=200, random_state=42)\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "# Train Gradient Boosting with best parameters\n",
    "gb_best = GradientBoostingRegressor(learning_rate=0.05, max_depth=5, min_samples_split=2, n_estimators=100, random_state=42)\n",
    "gb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "MAE: 0.6348383893409685, MSE: 1.0024937634551936, R²: 0.4933804867367567\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "MAE: 0.650770566900301, MSE: 1.0047270918433497, R²: 0.49225185354001244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions\n",
    "rf_preds = rf_best.predict(X_test)\n",
    "gb_preds = gb_best.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_mae = mean_absolute_error(y_test, rf_preds)\n",
    "rf_mse = mean_squared_error(y_test, rf_preds)\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "# Evaluate Gradient Boosting\n",
    "gb_mae = mean_absolute_error(y_test, gb_preds)\n",
    "gb_mse = mean_squared_error(y_test, gb_preds)\n",
    "gb_r2 = r2_score(y_test, gb_preds)\n",
    "\n",
    "# Print results\n",
    "print(\"Random Forest Performance:\")\n",
    "print(f\"MAE: {rf_mae}, MSE: {rf_mse}, R²: {rf_r2}\\n\")\n",
    "\n",
    "print(\"Gradient Boosting Performance:\")\n",
    "print(f\"MAE: {gb_mae}, MSE: {gb_mse}, R²: {gb_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
